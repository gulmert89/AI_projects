{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from cvlib import detect_face\n",
    "from keras.models import load_model\n",
    "from PIL.Image import open as Image_open\n",
    "model = load_model(\"best_model.h5\") # Loading the pretrained model to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take sample images from Google for each class and name them as the ones (i.e <code>\"sad.jpg\"</code>) below. Now, let's find out the class numbers that the model will assign because sometimes we end up arbitrary numbers instead of our class numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy: [[1.2646025e-04 1.6763769e-03 9.1766296e-03 9.8902053e-01]]\n",
      "sad: [[0.04921061 0.7129909  0.20824736 0.02955114]]\n",
      "shocked: [[9.9780884e-08 1.1519273e-05 9.9998438e-01 4.0535142e-06]]\n",
      "poker face: [[0.12971415 0.35642865 0.47015446 0.04370266]]\n"
     ]
    }
   ],
   "source": [
    "# Get image > Convert to numpy array > Resize it to our model's input_shape:\n",
    "happy_img = cv2.resize((np.array(Image_open(\"happy.jpg\"))), (64,64))\n",
    "sad_img = cv2.resize((np.array(Image_open(\"sad.jpg\"))), (64,64))\n",
    "shocked_img = cv2.resize((np.array(Image_open(\"shocked.jpg\"))), (64,64))\n",
    "neutral_img = cv2.resize((np.array(Image_open(\"neutral.jpg\"))), (64,64))\n",
    "# Convert to grayscale > Normalize them:\n",
    "happy_img = cv2.cvtColor(happy_img, code=6) / 255.0\n",
    "sad_img = cv2.cvtColor(sad_img, code=6) / 255.0\n",
    "shocked_img = cv2.cvtColor(shocked_img, code=6) / 255.0\n",
    "neutral_img = cv2.cvtColor(neutral_img, code=6) / 255.0\n",
    "# Add dimensions to match the model shape\n",
    "# i.e (IMG_COUNT, IMG_DIMENSION, IMG_DIMENSION, COLOR_CHANNEL)\n",
    "# (1, 64, 64, 1)\n",
    "happy_img = np.expand_dims(happy_img, axis=[0,3])\n",
    "sad_img = np.expand_dims(sad_img, axis=[0,3])\n",
    "shocked_img = np.expand_dims(shocked_img, axis=[0,3])\n",
    "neutral_img = np.expand_dims(neutral_img, axis=[0,3])\n",
    "\n",
    "print(\"happy:\", model.predict(happy_img))\n",
    "print(\"sad:\", model.predict(sad_img))\n",
    "print(\"shocked:\", model.predict(shocked_img))\n",
    "print(\"poker face:\", model.predict(neutral_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassName(classIndex):\n",
    "    \"A basic function to get the class name.\"\n",
    "    if classIndex == 3: return \"Happy\"\n",
    "    elif classIndex == 1: return \"Sad\"\n",
    "    elif classIndex == 2: return \"Shocked\"\n",
    "    else: return \"Poker Face\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# If a video name is entered, captures the specified video.\n",
    "\n",
    "detectFace_threshold = 0.80\n",
    "predictFace_threshold = 0.39 * 100\n",
    "\n",
    "try:\n",
    "    while cap.isOpened(): # Repeats until a key is pressed.\n",
    "\n",
    "        ret, frame = cap.read() # Starts capturing. \n",
    "        # 'ret' is True or False to represent if capturing is successful.\n",
    "        # 'frame' is the image to process.\n",
    "        if not ret:\n",
    "            print(\"Can't receive the frame.\")\n",
    "            break\n",
    "\n",
    "        # FACE RECOGNITION\n",
    "        faces, confidences = detect_face(frame, threshold=detectFace_threshold)\n",
    "        for f in faces:\n",
    "            # corner points of facial frame: \n",
    "            (startX, startY) = (f[0], f[1])    # top left corner\n",
    "            (endX, endY) = (f[2], f[3])    # bottom right corner\n",
    "            # crop it from the whole frame:\n",
    "            cropped_frame = np.copy(frame[startY:endY, startX:endX])        \n",
    "            # skip too small frames (10x10 pixels)\n",
    "            if (cropped_frame.shape[0]) < 10 or (cropped_frame.shape[1]) < 10:\n",
    "                continue\n",
    "\n",
    "            # preprocessing on the cropped frame\n",
    "            cropped_frame = cv2.resize(cropped_frame, (64,64))        \n",
    "            cropped_frame = cv2.cvtColor(cropped_frame, code=6)    # convert to grayscale\n",
    "            cropped_frame = cropped_frame.astype(\"float32\") / 255.0\n",
    "            cropped_frame = np.expand_dims(cropped_frame, axis=[0,3])\n",
    "            confidences = model.predict(cropped_frame)[0]    # probability value\n",
    "            max_probability = max(confidences)*100\n",
    "            classIndex = np.argmax(confidences)\n",
    "            className = getClassName(classIndex)\n",
    "\n",
    "            # different colors for different sentiments\n",
    "            if max_probability > predictFace_threshold:\n",
    "                frame_text = f\"{className} ({int(max_probability)}%)\"\n",
    "                # BLUE - GREEN - RED rgb(218,112,214)\n",
    "                if className == \"Shocked\":\n",
    "                    rect_color = text_color = (0, 255, 255)\n",
    "                elif className == \"Sad\":\n",
    "                    rect_color = text_color = (255, 0, 0)\n",
    "                elif className == \"Happy\":\n",
    "                    rect_color = text_color = (0, 255, 0)\n",
    "                elif className == \"Poker Face\":\n",
    "                    rect_color = text_color = (214, 112, 218)\n",
    "\n",
    "            else:\n",
    "                rect_color = text_color = (0, 0, 255)\n",
    "                frame_text = \"Reading...\"    \n",
    "\n",
    "            cv2.rectangle(img=frame, \n",
    "                          pt1=(startX, startY), \n",
    "                          pt2=(endX, endY), \n",
    "                          color=rect_color, \n",
    "                          thickness=2)\n",
    "\n",
    "            # let's keep the text in the frame and avoid edges:\n",
    "            startY = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.putText(img=frame, \n",
    "                        text=frame_text, \n",
    "                        org=(startX, startY), \n",
    "                        fontFace=cv2.FONT_HERSHEY_COMPLEX, \n",
    "                        lineType=cv2.LINE_AA,\n",
    "                        fontScale=0.6, \n",
    "                        color=text_color, \n",
    "                        thickness=1)\n",
    "\n",
    "        cv2.imshow(\"Face_Sentiment\", frame)\n",
    "        cv2.imwrite(\"saved_picture.jpg\", frame)\n",
    "        if cv2.waitKey(1) > 0:    # Repeats until a key is pressed.\n",
    "            break\n",
    "\n",
    "    cap.release() # Releases the camera after a key is pressed\n",
    "    cv2.destroyWindow(\"Face_Sentiment\") # Closes the window named \"Face_Sentiment\"\n",
    "    # cv2.waitKey() # Necessary for not having trouble with the closing window\n",
    "except:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
